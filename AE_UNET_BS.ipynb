{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eTOZA53eAcJY",
    "outputId": "1d4bc35a-4655-43ec-d14b-543340a8e11b"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # images\n",
    "from PIL import Image\n",
    "import numpy as np #numpy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v2 as tf #use tensorflow v2 as a main\n",
    "import tensorflow.keras as keras # required for high level applications\n",
    "from sklearn.model_selection import train_test_split # split for validation sets\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize # normalization of the matrix\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Concatenate, Dense, Flatten, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.utils import normalize,Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mix loss in section name** = mixed_loss_l2 <br>\n",
    "**Advanced/another Mix loss in section name** = mixed_loss_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1oBIgLVvlh6"
   },
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VR9_4qervll2"
   },
   "outputs": [],
   "source": [
    "def data_generator(images, batch_size):\n",
    "    num_samples = len(images)\n",
    "    while True:\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_images = images[batch_indices]\n",
    "            yield batch_images, batch_images\n",
    "\n",
    "    \n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5,          \n",
    "    patience=5,          \n",
    "    min_lr=1e-7,         \n",
    "    verbose=1         \n",
    ")\n",
    "\n",
    "class ShowReconstruction(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "      rand_id = np.random.randint(len(source_images))\n",
    "      source_image = source_images[rand_id][np.newaxis,...]\n",
    "      reconstructed = self.model.predict(source_image)\n",
    "      real_image = target_images[rand_id]\n",
    "\n",
    "      plt.subplot(1,3,1)\n",
    "      plt.imshow(source_image[0], cmap='gray')\n",
    "      plt.title(\"Source Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.subplot(1,3,2)\n",
    "      plt.imshow(reconstructed[0], cmap='gray')\n",
    "      plt.title(\"Produced Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.subplot(1,3,3)\n",
    "      plt.imshow(real_image, cmap='gray')\n",
    "      plt.title(\"Real Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.tight_layout()\n",
    "      #plt.savefig(\"Reconstruction_Epoch_{}\".format(epoch))\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18xTl6LkMSSd",
    "tags": []
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsOvPpkZMU0_"
   },
   "outputs": [],
   "source": [
    "#MS-SSIM\n",
    "def ms_ssim_loss(y_true, y_pred, max_val=1.0):\n",
    "    # You don't need to transpose for grayscale images\n",
    "    y_true = tf.image.convert_image_dtype(y_true, tf.float32)\n",
    "    y_pred = tf.image.convert_image_dtype(y_pred, tf.float32)\n",
    "    ms_ssim = 1.0 - tf.image.ssim_multiscale(y_true, y_pred, max_val=max_val)\n",
    "    return ms_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHNytrF6MU3I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loss of MSE + MS-SSIM\n",
    "def mixed_loss_l2(y_true, y_pred, alpha=0.84, max_val=1.0):\n",
    "    y_true = tf.image.convert_image_dtype(y_true, tf.float32)\n",
    "    y_pred = tf.image.convert_image_dtype(y_pred, tf.float32)\n",
    "    \n",
    "    mse_loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "    ms_ssim = 1.0 - tf.image.ssim_multiscale(y_true, y_pred, max_val=max_val)\n",
    "    \n",
    "    mix = alpha * ms_ssim + (1-alpha) * mse_loss\n",
    "    return mix\n",
    "\n",
    "def mixed_loss_l1(y_true, y_pred, max_val=1.0):\n",
    "    mae_loss = tf.keras.losses.MeanAbsoluteError()(y_true, y_pred)\n",
    "    return 0.16 * mae_loss + 0.84 * (1.0 - tf.image.ssim_multiscale(y_true, y_pred, max_val=max_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_ssim_metric(y_true, y_pred):\n",
    "    return tf.image.ssim_multiscale(y_true, y_pred, max_val=tf.reduce_max(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def psnr(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    mse = K.mean(K.square(y_true - y_pred))\n",
    "    psnr = 10.0 * K.log((max_pixel**2) / mse) / K.log(10.0)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oIRWiHrnLtf"
   },
   "source": [
    "# Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsFXjWIMnZir",
    "outputId": "9f8e7f4b-7227-4427-a309-ce58f376659b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_folder = 'Dataset/source'\n",
    "target_folder = 'Dataset/target'\n",
    "\n",
    "# List all image file names in the source folder\n",
    "source_image_files = os.listdir(source_folder)\n",
    "\n",
    "# Initialize lists to store the preprocessed images\n",
    "source_images = []\n",
    "target_images = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Loop through each image file in the source folder\n",
    "for filename in source_image_files:\n",
    "\n",
    "     # Load source image\n",
    "    source_image = cv2.imread(os.path.join(source_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    source_image = source_image.astype('float32') / 255.0\n",
    "    #source_image = (source_image.astype(np.float32) - 127.5) / 127.5\n",
    "    #source_image = np.repeat(source_image[:, :, np.newaxis], 3, axis=2)\n",
    "    source_image = cv2.resize(source_image, (512, 512))\n",
    "    source_images.append(source_image)\n",
    "\n",
    "    # Load corresponding target image from the target folder\n",
    "    target_image = cv2.imread(os.path.join(target_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    target_image = target_image.astype('float32') / 255.0\n",
    "    #target_image = (target_image.astype(np.float32) - 127.5) / 127.5\n",
    "    #target_image = np.repeat(target_image[:, :, np.newaxis], 3, axis=2)\n",
    "    target_image = cv2.resize(target_image, (512, 512))\n",
    "    target_images.append(target_image)\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "    if i == 500:\n",
    "        break\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "source_images = np.array(source_images)\n",
    "target_images = np.array(target_images)\n",
    "\n",
    "source_images = np.expand_dims(source_images, axis=-1)\n",
    "target_images = np.expand_dims(target_images, axis=-1)\n",
    "# Print the shape of the loaded and preprocessed images\n",
    "print(\"Source Images Shape:\", source_images.shape)\n",
    "print(\"Target Images Shape:\", target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first 100 as a test set\n",
    "X_train = source_images[100:]\n",
    "y_train = target_images[100:]\n",
    "\n",
    "X_val = source_images[:100]\n",
    "y_val = target_images[:100]\n",
    "\n",
    "print(f\"x_train: {len(X_train)} | x_val: {len(X_val)} | y_train: {len(y_train)} | y_val: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the whole dataset, the DataGenerator needs to be used\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle dataset test\n",
    "test_folder = 'Dataset/test/'\n",
    "\n",
    "source_image_files = os.listdir(test_folder)\n",
    "\n",
    "source_image_files = [filename for filename in source_image_files if filename.lower().endswith('.png')]\n",
    "   \n",
    "test_images = []\n",
    "\n",
    "i = 0\n",
    "for filename in source_image_files:\n",
    "    test_image = cv2.imread(os.path.join(test_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    test_image = cv2.resize(test_image, (1024, 1024))\n",
    "    #test_image = cv2.bitwise_not(test_image)\n",
    "    test_image = test_image.astype('float32') / 255.0\n",
    "    test_images.append(test_image)\n",
    "    if i == 4:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "print(\"Test Images Shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided images from Olomouc\n",
    "test_folder = 'Test/'\n",
    "\n",
    "source_image_files = os.listdir(test_folder)\n",
    "\n",
    "source_image_files = [filename for filename in source_image_files if filename.lower().endswith('.png')]\n",
    "   \n",
    "test_images = []\n",
    "\n",
    "for filename in source_image_files:\n",
    "    test_image = cv2.imread(os.path.join(test_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    test_image = cv2.resize(test_image, (512, 512))\n",
    "    #test_image = cv2.bitwise_not(test_image)\n",
    "    test_image = test_image.astype('float32') / 255.0\n",
    "    test_images.append(test_image)\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "print(\"Test Images Shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "YyCkHw9TEpAV",
    "outputId": "c11cc32f-11f1-4ca3-a009-6886622912fb"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, axs = plt.subplots(2, 5)\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "      if i == 0:\n",
    "            axs[i, j].imshow(source_images[j], cmap='gray')\n",
    "            axs[i, j].set_title('Source image')\n",
    "            axs[i, j].axis('off')\n",
    "      else:\n",
    "            axs[i, j].imshow(target_images[j], cmap='gray')\n",
    "            axs[i, j].set_title('Target image')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btbieR9-tQNb"
   },
   "source": [
    "# Autoencoder models for bone suppresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 400/100 Train images 1024x1024x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyL59VBLqvnV",
    "outputId": "b4c27f22-def0-4801-abdf-383054d05cc3"
   },
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "#encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "#decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder) #Change to decoder if using code above\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mse\", metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiGsRWZVrNF2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  with tf.device('/device:GPU:1'):\n",
    "    train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "    test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "    history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[ShowReconstruction(), reduce_lr_callback],\n",
    "    shuffle=True,\n",
    "    workers=8\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeF41G4PvUsK",
    "outputId": "9e19ed01-40d0-4abb-ca1f-28091aee27d2"
   },
   "outputs": [],
   "source": [
    "model.save('AE_MSE_50epochs_400.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=ms_ssim_loss, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback],\n",
    "shuffle=True,\n",
    "workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MSSSIM_50epochs_400.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "model = load_model('AE_MSSSIM_50epochs_400.h5', custom_objects={'ms_ssim_loss' : ms_ssim_loss,'ms_ssim_metric' : ms_ssim_metric, 'psnr' : psnr})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MSSSIM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "\n",
    "model = load_model('AE_MSSSIM.h5', custom_objects={'ms_ssim_loss': ms_ssim_loss, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  with tf.device('/device:GPU:1'):\n",
    "    train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "    test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "    history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[ShowReconstruction(), reduce_lr_callback],\n",
    "    shuffle=True,\n",
    "    workers=8\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MixLoss_50epochs_400.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model.evaluate(test_gen)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "model = load_model('AE_MixLoss_50epochs_400.h5', custom_objects={'mixed_loss_l2': mixed_loss_l2, 'ms_ssim_metric' : ms_ssim_metric, 'psnr':psnr})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000/100 Train images 1024x1024x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "#encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "#decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mse\", metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[reduce_lr_callback], #ShowReconstruction() commented since the validation inference cause the GPU to OOM\n",
    "shuffle=True,\n",
    "workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MSE_50epochs_1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "model = load_model('AE_MSE_50epochs_1000.h5', custom_objects={'ms_ssim_metric' : ms_ssim_metric, 'psnr' : psnr})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=ms_ssim_loss, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback],\n",
    "shuffle=True,\n",
    "workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MSSSIM_50epochs_1000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "model = load_model('AE_MSSSIM_50epochs_1000.h5', custom_objects={'ms_ssim_loss': ms_ssim_loss, 'ms_ssim_metric' : ms_ssim_metric, 'psnr':psnr})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback],\n",
    "shuffle=True,\n",
    "workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MixLoss_50epochs_1000train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "model = load_model('AE_MixLoss_50epochs_1000train.h5', custom_objects={'mixed_loss_l2': mixed_loss_l2, 'ms_ssim_metric' : ms_ssim_metric, 'psnr':psnr})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mse\", metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  with tf.device('/device:GPU:1'):\n",
    "    history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MSE_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=ms_ssim_loss, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 16\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MSSIM_60epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "model = load_model('AE_MSSIM_60epochs_full.h5', custom_objects={'ms_ssim_loss': ms_ssim_loss, 'ms_ssim_metric' : ms_ssim_metric, 'psnr':psnr})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 16\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_MixLoss_60epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('AE_MixLoss_50epochs_full.h5', custom_objects={'mixed_loss_l2': mixed_loss_l2, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using another Mix Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "#encoder = Conv2D(1024, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "#decoder = Conv2D(1024, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "\n",
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:GPU:1'):\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l1, metrics=[\"MSE\", \"MAE\", ms_ssim_metric, psnr])\n",
    "    model.summary()\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_AdvMixLoss_100epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50epoch\n",
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model.evaluate(test_gen)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model.evaluate(test_gen)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('AE_MixLoss_50epochs_full.h5', custom_objects={'mixed_loss_l1': mixed_loss_l1, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained backones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwYTJuLKF9Xq",
    "outputId": "b914c461-2434-43e9-e249-daa4dd00ea6f"
   },
   "outputs": [],
   "source": [
    "def build_unet_with_resnet(input_size=(source_images.shape[1],source_images.shape[2],1)):\n",
    "    input_img = Input(shape=input_size)\n",
    "\n",
    "    # Expand the single-channel input to three channels\n",
    "    expanded_input = tf.keras.layers.Lambda(lambda x: tf.concat([x, x, x], axis=-1))(input_img)\n",
    "\n",
    "    # Pre-trained ResNet as the encoder\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(1024, 1024, 3))\n",
    "\n",
    "    # Extract features from the ResNet model\n",
    "    encoder_output = base_model(expanded_input)\n",
    "\n",
    "    # Decoder part of the U-Net\n",
    "    x = Conv2D(1024, (3, 3), activation='relu', padding='same')(encoder_output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    #x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "    return Model(inputs=input_img, outputs=decoded)\n",
    "\n",
    "model = build_unet_with_resnet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIKZOt2LJjSg"
   },
   "outputs": [],
   "source": [
    "epochs = 48\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "00uWxP_YJjU7",
    "outputId": "7346934c-32e9-4454-ccca-42647440f1d3"
   },
   "outputs": [],
   "source": [
    "model.save('AE_Resnet_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vn_3Eq5BOV-b",
    "outputId": "04e4866f-4b50-4ce9-8e51-91a0e343a36e"
   },
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('UNET_Resnet_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_with_effnet(input_size=(source_images.shape[1],source_images.shape[2],1)):\n",
    "    input_img = Input(shape=input_size)\n",
    "\n",
    "    # Expand the single-channel input to three channels\n",
    "    expanded_input = tf.keras.layers.Lambda(lambda x: tf.concat([x, x, x], axis=-1))(input_img)\n",
    "\n",
    "    # Pre-trained ResNet as the encoder\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(1024, 1024, 3))\n",
    "    \n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Extract features from the ResNet model\n",
    "    encoder_output = base_model(expanded_input)\n",
    "\n",
    "    # Decoder part of the U-Net\n",
    "    x = Conv2D(1024, (3, 3), activation='relu', padding='same')(encoder_output)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    #x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = UpSampling2D((2, 2))(x)\n",
    "    # Output layer\n",
    "    decoded = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Create the model\n",
    "    return Model(inputs=input_img, outputs=decoded)\n",
    "\n",
    "model = build_unet_with_effnet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_EfficientNet_50epochs_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('UNET_Resnet_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPN Model with EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(1024, 1024, 1))\n",
    "expanded_input = tf.keras.layers.Lambda(lambda x: tf.concat([x, x, x], axis=-1))(input_img)\n",
    "\n",
    "# Pre-trained ResNet as the encoder\n",
    "efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=expanded_input)\n",
    "\n",
    "# FPN layers\n",
    "C2 = efficientnet.get_layer('block2a_expand_activation').output\n",
    "C3 = efficientnet.get_layer('block3a_expand_activation').output\n",
    "C4 = efficientnet.get_layer('block4a_expand_activation').output\n",
    "C5 = efficientnet.get_layer('block6a_expand_activation').output\n",
    "\n",
    "# Top-down pathway\n",
    "P5 = Conv2D(256, (1, 1), activation='relu', padding='same')(C5)\n",
    "P4 = Conv2D(256, (1, 1), activation='relu', padding='same')(C4) + UpSampling2D()(P5)\n",
    "P3 = Conv2D(256, (1, 1), activation='relu', padding='same')(C3) + UpSampling2D()(P4)\n",
    "P2 = Conv2D(256, (1, 1), activation='relu', padding='same')(C2) + UpSampling2D()(P3)\n",
    "\n",
    "P2 = UpSampling2D()(P2)\n",
    "\n",
    "# Decoder layers\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(P2)  # Output should match the input shape (3 channels)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=input_img, outputs=decoded)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('FPN_EfficientNet_100epochs_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('UNET_Resnet_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlWmbpf0MY07"
   },
   "source": [
    "# U-Net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net default architecture | MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIfJQgrBMY8U",
    "outputId": "f857c979-a65c-4536-fcf9-c1e8ab65f77c"
   },
   "outputs": [],
   "source": [
    "def unet(input_size=(source_images.shape[1],source_images.shape[2],1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    c10 = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs], outputs=[c10])\n",
    "\n",
    "model = unet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mse\", metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('UNET_MSE_50epochs_full.h5', custom_objects={'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kU1SlC9d2bkP",
    "outputId": "8d825255-859f-426d-c67c-5eddb766552b"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('UNET_MSE_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model = load_model('UNET_MSE_50epochs_full.h5', custom_objects={'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "        predicted_images = model.predict(test_images)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net default architecture | MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size=(source_images.shape[1],source_images.shape[2],1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    c10 = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs], outputs=[c10])\n",
    "\n",
    "model = unet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=ms_ssim_loss, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('UNET_MSSIM_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net default architecture | Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unet(input_size=(source_images.shape[1],source_images.shape[2],1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    c10 = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs], outputs=[c10])\n",
    "\n",
    "model = unet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('UNET_Mixloss_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model.evaluate(test_gen)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model = load_model('UNET_Mixloss_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "        predicted_images = model.predict(test_images)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation models from pre-trained library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SM-Unet | Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb0', input_shape=(1024,1024, 1), encoder_weights=None)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "checkpoint_path = 'best_model.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Unet_SM_EfficientNet_50epochs_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('Unet_SM_EfficientNet_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SM-Unet | Another Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb0', input_shape=(1024,1024, 1), encoder_weights=None)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l1, metrics=[\"MSE\",\"MAE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "checkpoint_path = 'best_model.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Unet_SM_EfficientNet_adv_50epochs_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('Unet_SM_EfficientNet_adv_50epochs_full.h5', custom_objects={'loss_mix':loss_mix,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "    \n",
    "    \n",
    "    predicted_image = cv2.normalize(predicted_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    predicted_image = np.uint8(predicted_image)\n",
    "    predicted_image = cv2.bitwise_not(predicted_image)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model = load_model('AE_MixLoss_60epochs_full.h5', custom_objects={'mixed_loss_l1':mixed_loss_l1,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "        predicted_images = model.predict(test_images)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SM-FPN | Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.FPN('resnet50', encoder_weights=None, activation=\"sigmoid\", classes=1)\n",
    "    \n",
    "inp = Input(shape=(None, None, 1))\n",
    "l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
    "out = model(l1)\n",
    "\n",
    "model = Model(inp, out, name=model.name)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "checkpoint_path = 'best_model.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('FPN_SM_ResNet50_50epochs_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:GPU:1'):\n",
    "    model = load_model('FPN_SM_ResNet50_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "    model.evaluate(test_gen)\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SM-FPN | EfficientNet Mix Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.FPN('efficientnetb0', encoder_weights=None, activation=\"sigmoid\", classes=1)\n",
    "\n",
    "inp = Input(shape=(None, None, 1))\n",
    "l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
    "out = model(l1)\n",
    "\n",
    "model = Model(inp, out, name=model.name)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "checkpoint_path = 'best_model.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('FPN_SM_EfficientNet_50epochs_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:GPU:1'):\n",
    "    model = load_model('FPN_SM_EfficientNet_50epochs_full.h5', custom_objects={'loss_mix':loss_mix,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "    model.evaluate(test_gen)\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "#model = load_model('FPN_SM_EfficientNet_50epochs_full.h5', custom_objects={'loss_mix':loss_mix,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "    predicted_image_invert = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation model + inverted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'Dataset/source'\n",
    "target_folder = 'Dataset/target'\n",
    "\n",
    "# List all image file names in the source folder\n",
    "source_image_files = os.listdir(source_folder)\n",
    "\n",
    "# Initialize lists to store the preprocessed images\n",
    "source_images = []\n",
    "target_images = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Loop through each image file in the source folder\n",
    "for filename in source_image_files:\n",
    "    \n",
    "    # Load source image\n",
    "    source_image = cv2.imread(os.path.join(source_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    source_image = source_image.astype('float32') / 255.0\n",
    "    source_images.append(source_image)\n",
    "\n",
    "    # Load corresponding target image from the target folder\n",
    "    target_image = cv2.imread(os.path.join(target_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    target_image = target_image.astype('float32') / 255.0\n",
    "    target_images.append(target_image)\n",
    "    \n",
    "    #Add bitwise inverted images:\n",
    "    if i > 100: \n",
    "        source_image = cv2.imread(os.path.join(source_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        source_image = cv2.bitwise_not(source_image)\n",
    "        source_image = source_image.astype('float32') / 255.0\n",
    "        source_images.append(source_image)\n",
    "\n",
    "        target_image = cv2.imread(os.path.join(target_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        target_image = cv2.bitwise_not(target_image)\n",
    "        target_image = target_image.astype('float32') / 255.0\n",
    "        target_images.append(target_image)\n",
    "    \n",
    "    # Resize images if needed (adjust the dimensions)\n",
    "    #source_image = cv2.resize(source_image, (512, 512))\n",
    "    #target_image = cv2.resize(target_image, (512, 512))\n",
    "    \n",
    "    i += 1\n",
    "    #if i == 500:\n",
    "    #    break\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "source_images = np.array(source_images)\n",
    "target_images = np.array(target_images)\n",
    "\n",
    "source_images = np.expand_dims(source_images, axis=-1)\n",
    "target_images = np.expand_dims(target_images, axis=-1)\n",
    "# Print the shape of the loaded and preprocessed images\n",
    "print(\"Source Images Shape:\", source_images.shape)\n",
    "print(\"Target Images Shape:\", target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first 100 as a test set\n",
    "X_train = source_images[100:]\n",
    "y_train = target_images[100:]\n",
    "\n",
    "X_val = source_images[:100]\n",
    "y_val = target_images[:100]\n",
    "\n",
    "print(f\"x_train: {len(X_train)} | x_val: {len(X_val)} | y_train: {len(y_train)} | y_val: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, axs = plt.subplots(2, 5)\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "      if i == 0:\n",
    "            axs[i, j].imshow(source_images[j], cmap='gray')\n",
    "            axs[i, j].set_title('Source image')\n",
    "            axs[i, j].axis('off')\n",
    "      else:\n",
    "            axs[i, j].imshow(target_images[j], cmap='gray')\n",
    "            axs[i, j].set_title('Target image')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.FPN('efficientnetb0', encoder_weights=None, activation=\"sigmoid\", classes=1)\n",
    "\n",
    "inp = Input(shape=(None, None, 1))\n",
    "l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
    "out = model(l1)\n",
    "\n",
    "model = Model(inp, out, name=model.name)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "    predicted_image_invert = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net Mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb0', input_shape=(1024,1024, 1), encoder_weights=None)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After 50epochs\n",
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "    predicted_image_invert = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Unet_SM_EfficientNet_100epochs_invertedfull.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After 100epochs\n",
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "    predicted_image_invert = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net | Advanced mix loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb0', input_shape=(1024,1024, 1), encoder_weights=None)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l1, metrics=[\"MSE\", \"MAE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('Unet_SM_EfficientNet_adv_50epochs_inverted_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After 50epochs\n",
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Unet_SM_EfficientNet_adv_100epochs_inverted_full.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After 100epochs\n",
    "model.evaluate(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "    predicted_image_invert = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of AE and U-net on 512x512x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE + Mixed L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():    \n",
    "input_shape = (source_images.shape[1],source_images.shape[2], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "encoder = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "#encoder = Conv2D(1024, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#encoder = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "\n",
    "# Decoder\n",
    "#decoder = Conv2D(1024, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l1, metrics=[\"MSE\", \"MAE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[reduce_lr_callback] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AE_512_MixedL1Loss_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPN + EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(512, 512, 1))\n",
    "expanded_input = tf.keras.layers.Lambda(lambda x: tf.concat([x, x, x], axis=-1))(input_img)\n",
    "\n",
    "# Pre-trained ResNet as the encoder\n",
    "efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=expanded_input)\n",
    "\n",
    "# FPN layers\n",
    "C2 = efficientnet.get_layer('block2a_expand_activation').output\n",
    "C3 = efficientnet.get_layer('block3a_expand_activation').output\n",
    "C4 = efficientnet.get_layer('block4a_expand_activation').output\n",
    "C5 = efficientnet.get_layer('block6a_expand_activation').output\n",
    "\n",
    "# Top-down pathway\n",
    "P5 = Conv2D(256, (1, 1), activation='relu', padding='same')(C5)\n",
    "P4 = Conv2D(256, (1, 1), activation='relu', padding='same')(C4) + UpSampling2D()(P5)\n",
    "P3 = Conv2D(256, (1, 1), activation='relu', padding='same')(C3) + UpSampling2D()(P4)\n",
    "P2 = Conv2D(256, (1, 1), activation='relu', padding='same')(C2) + UpSampling2D()(P3)\n",
    "\n",
    "P2 = UpSampling2D()(P2)\n",
    "\n",
    "# Decoder layers\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(P2) \n",
    "\n",
    "model = tf.keras.Model(inputs=input_img, outputs=decoded)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[reduce_lr_callback] \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('FPN_512_EfficientNet_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net + Another Mixed Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unet(input_size=(source_images.shape[1],source_images.shape[2],1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    c10 = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs], outputs=[c10])\n",
    "\n",
    "model = unet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('UNET_512_Mixloss_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "try:\n",
    "    with tf.device('/device:GPU:1'):\n",
    "        model = load_model('UNET_Mixloss_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})\n",
    "        predicted_images = model.predict(test_images)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "num_samples_to_visualize = 5\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[idx].squeeze()\n",
    "    predicted_image = predicted_images[idx].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SM U-net + Mixed L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb0', input_shape=(512,512, 1), encoder_weights=None) \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mixed_loss_l2, metrics=[\"MSE\", ms_ssim_metric, psnr])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(X_val, y_val, batch_size)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "history = model.fit(\n",
    "train_gen,\n",
    "validation_data=test_gen,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "callbacks=[ShowReconstruction(), reduce_lr_callback, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Unet_512_SM_EfficientNet_50epochs_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Unet_512_SM_EfficientNet_50epochs_full.h5', custom_objects={'mixed_loss_l2':mixed_loss_l2,'psnr': psnr, 'ms_ssim_metric' : ms_ssim_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator(X_val, y_val, 4)\n",
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = model.predict(test_images)\n",
    "\n",
    "\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = test_images[i].squeeze()\n",
    "    predicted_image = predicted_images[i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
