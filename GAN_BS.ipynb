{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90c781a-9b8e-43e6-a69c-870a777e8f34",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22022044-70c9-400d-843d-9a6f292a6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # images\n",
    "import numpy as np #numpy\n",
    "import time\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v2 as tf #use tensorflow v2 as a main\n",
    "import tensorflow.keras as keras # required for high level applications\n",
    "from sklearn.model_selection import train_test_split # split for validation sets\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize # normalization of the matrix\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose, Concatenate, Flatten, Dense\n",
    " \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d74bd7",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48172e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_ssim_metric(y_true, y_pred):\n",
    "    return tf.image.ssim_multiscale(y_true, y_pred, max_val=tf.reduce_max(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def psnr(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    mse = K.mean(K.square(y_true - y_pred))\n",
    "    psnr = 10.0 * K.log((max_pixel**2) / mse) / K.log(10.0)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2612f57",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad7bc1-f9e1-4447-b22e-851bc8ca9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5,          \n",
    "    patience=5,          \n",
    "    min_lr=1e-7,         \n",
    "    verbose=1         \n",
    ")\n",
    "\n",
    "class ShowReconstruction(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "      rand_id = np.random.randint(len(source_images))\n",
    "      source_image = source_images[rand_id][np.newaxis,...]\n",
    "      reconstructed = self.model.predict(source_image)\n",
    "      real_image = target_images[rand_id]\n",
    "\n",
    "      plt.subplot(1,3,1)\n",
    "      plt.imshow(source_image[0], cmap='gray')\n",
    "      plt.title(\"Source Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.subplot(1,3,2)\n",
    "      plt.imshow(reconstructed[0], cmap='gray')\n",
    "      plt.title(\"Produced Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.subplot(1,3,3)\n",
    "      plt.imshow(real_image, cmap='gray')\n",
    "      plt.title(\"Real Image\")\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.tight_layout()\n",
    "      #plt.savefig(\"Reconstruction_Epoch_{}\".format(epoch))\n",
    "      plt.show()\n",
    "            \n",
    "def normalize_images(images):\n",
    "    #Normalize from [-1,1] to [0,1] for the metrics\n",
    "    return (images + 1.0) / 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96950128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(generator, X_val, y_val,batch_size= 4):\n",
    "    num_samples = len(X_val)\n",
    "    steps = num_samples // batch_size + (1 if num_samples % batch_size else 0)\n",
    "    \n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    for step in range(steps):\n",
    "        batch_start = step * batch_size\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        X_batch = X_val[batch_start:batch_end]\n",
    "        y_batch = y_val[batch_start:batch_end]\n",
    "        \n",
    "        predicted_batch = generator.predict(X_batch)\n",
    "        # Normalize images from [-1, 1] to [0, 1] for PSNR and SSIM calculations\n",
    "        predicted_batch = normalize_images(predicted_batch)\n",
    "        y_batch_normalized = normalize_images(y_batch)\n",
    "        \n",
    "        for i in range(batch_end - batch_start):\n",
    "            psnr_val = psnr(y_batch_normalized[i], predicted_batch[i])\n",
    "            ssim_val = ms_ssim_metric(y_batch_normalized[i], predicted_batch[i])\n",
    "            \n",
    "            psnr_values.append(psnr_val)\n",
    "            ssim_values.append(ssim_val)\n",
    "    \n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    \n",
    "    return avg_psnr, avg_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953e5ab-1ea5-4d83-828f-a1333c1c0573",
   "metadata": {
    "id": "7oIRWiHrnLtf"
   },
   "source": [
    "# Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29937af-2649-4979-aa35-0fa0250a765f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsFXjWIMnZir",
    "outputId": "9f8e7f4b-7227-4427-a309-ce58f376659b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_folder = 'Dataset/source'\n",
    "target_folder = 'Dataset/target'\n",
    "\n",
    "# List all image file names in the source folder\n",
    "source_image_files = os.listdir(source_folder)\n",
    "\n",
    "# Initialize lists to store the preprocessed images\n",
    "source_images = []\n",
    "target_images = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Loop through each image file in the source folder\n",
    "for filename in source_image_files:\n",
    "\n",
    "    # Load source image\n",
    "    source_image = cv2.imread(os.path.join(source_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    #source_image = source_image.astype('float32') / 255.0\n",
    "    source_image = (source_image.astype(np.float32) - 127.5) / 127.5\n",
    "    source_image = np.repeat(source_image[:, :, np.newaxis], 3, axis=2)\n",
    "    source_image = cv2.resize(source_image, (512, 512))\n",
    "    source_images.append(source_image)\n",
    "\n",
    "    # Load corresponding target image from the target folder\n",
    "    target_image = cv2.imread(os.path.join(target_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    #target_image = target_image.astype('float32') / 255.0\n",
    "    target_image = (target_image.astype(np.float32) - 127.5) / 127.5\n",
    "    target_image = np.repeat(target_image[:, :, np.newaxis], 3, axis=2)\n",
    "    target_image = cv2.resize(target_image, (512, 512))\n",
    "    target_images.append(target_image)\n",
    "       \n",
    "    i += 1\n",
    "    if i == 3100:\n",
    "        break\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "source_images = np.array(source_images)\n",
    "target_images = np.array(target_images)\n",
    "\n",
    "#source_images = np.expand_dims(source_images, axis=-1)\n",
    "#target_images = np.expand_dims(target_images, axis=-1)\n",
    "# Print the shape of the loaded and preprocessed images\n",
    "print(\"Source Images Shape:\", source_images.shape)\n",
    "print(\"Target Images Shape:\", target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a34b0-490b-4156-b079-a4cd890ce758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first 100 as a test set\n",
    "X_train = source_images[100:]\n",
    "y_train = target_images[100:]\n",
    "\n",
    "X_val = source_images[:100]\n",
    "y_val = target_images[:100]\n",
    "\n",
    "print(f\"x_train: {len(X_train)} | x_val: {len(X_val)} | y_train: {len(y_train)} | y_val: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738e361-78ce-456b-b2e6-4a86103e08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle dataset test\n",
    "test_folder = 'Dataset/test/'\n",
    "\n",
    "source_image_files = os.listdir(test_folder)\n",
    "\n",
    "source_image_files = [filename for filename in source_image_files if filename.lower().endswith('.png')]\n",
    "   \n",
    "test_images = []\n",
    "\n",
    "i = 0\n",
    "for filename in source_image_files:\n",
    "    test_image = cv2.imread(os.path.join(test_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    test_image = cv2.resize(test_image, (1024, 1024))\n",
    "    #test_image = cv2.bitwise_not(test_image)\n",
    "    test_image = test_image.astype('float32') / 255.0\n",
    "    test_images.append(test_image)\n",
    "    if i == 4:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "print(\"Test Images Shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0885a5-20a3-42f9-9c6b-3993eac25c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided images from Olomouc\n",
    "test_folder = 'Test/'\n",
    "\n",
    "source_image_files = os.listdir(test_folder)\n",
    "\n",
    "source_image_files = [filename for filename in source_image_files if filename.lower().endswith('.png')]\n",
    "   \n",
    "test_images = []\n",
    "\n",
    "for filename in source_image_files:\n",
    "    test_image = cv2.imread(os.path.join(test_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    test_image = (test_image.astype(np.float32) - 127.5) / 127.5\n",
    "    test_image = np.repeat(test_image[:, :, np.newaxis], 3, axis=2)\n",
    "    test_image = cv2.resize(test_image, (1024, 1024))\n",
    "    #test_image = cv2.bitwise_not(test_image)\n",
    "    test_images.append(test_image)\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "print(\"Test Images Shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0e4a3-db61-484a-bf24-983d84e7fdb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "YyCkHw9TEpAV",
    "outputId": "c11cc32f-11f1-4ca3-a009-6886622912fb"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, axs = plt.subplots(2, 5)\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "      if i == 0:\n",
    "            axs[i, j].imshow(source_images[j], cmap='gray')\n",
    "            axs[i, j].set_title('Source image')\n",
    "            axs[i, j].axis('off')\n",
    "      else:\n",
    "            axs[i, j].imshow(target_images[j], cmap='gray')\n",
    "            axs[i, j].set_title('Target image')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba308b-c342-4367-a88d-1f661887d661",
   "metadata": {},
   "source": [
    "# Build GAN blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30d6dd-5dfd-42ba-b160-9b13aea88bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer='he_normal', padding='same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ed2b3-4b73-4945-9e26-bb4b26405eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_WGAN(input_shape, n_filters=64, dropout=0.5, batchnorm=True):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    c1 = conv2d_block(inputs, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    p5 = MaxPooling2D((2, 2))(c5)\n",
    "\n",
    "\n",
    "    cB = conv2d_block(p5, n_filters=n_filters*32, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "\n",
    "    u6 = Conv2DTranspose(n_filters*16, (3, 3), strides=(2, 2), padding='same')(cB)\n",
    "    u6 = Concatenate()([u6, c5]) \n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c4]) \n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c3]) \n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c2]) \n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u10 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same')(c9)\n",
    "    u10 = Concatenate()([u10, c1]) \n",
    "    c10 = conv2d_block(u10, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    outputs = Conv2D(3, (1, 1), activation='tanh')(c10)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc5555-3a87-4aed-8225-01252d69f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_WGAN(input_shape, n_filters=64):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    d1 = Conv2D(n_filters, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    d1 = layers.LeakyReLU(alpha=0.2)(d1)\n",
    "\n",
    "    d2 = Conv2D(n_filters*2, kernel_size=4, strides=2, padding='same')(d1)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = layers.LeakyReLU(alpha=0.2)(d2)\n",
    "\n",
    "    d3 = Conv2D(n_filters*4, kernel_size=4, strides=2, padding='same')(d2)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    d3 = layers.LeakyReLU(alpha=0.2)(d3)\n",
    "\n",
    "    d4 = Conv2D(n_filters*8, kernel_size=4, strides=2, padding='same')(d3)\n",
    "    d4 = BatchNormalization()(d4)\n",
    "    d4 = layers.LeakyReLU(alpha=0.2)(d4)\n",
    "\n",
    "    d5 = Conv2D(n_filters*16, kernel_size=4, strides=2, padding='same')(d4)\n",
    "    d5 = BatchNormalization()(d5)\n",
    "    d5 = layers.LeakyReLU(alpha=0.2)(d5)\n",
    "    \n",
    "    flat = Flatten()(d5)\n",
    "    outputs = Dense(1)(flat)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "#input_shape = (1024, 1024, 3)\n",
    "#discriminator_WGAN = discriminator_WGAN(input_shape)\n",
    "#discriminator_WGAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e6404-6d8f-48b2-87a0-070bcaa81575",
   "metadata": {},
   "source": [
    "## Wasserstein | 400train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff2493-7234-4263-bd2f-d31df6a63e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03de9f-c058-4338-8a71-2c14edad552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(source_images)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(target_images)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 8\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dce116-9293-4ba6-9016-44b340d2ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6c04a-22fb-4685-979c-48944e094b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_2500epochs_500data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a840671-5d78-4439-b4e8-2cf772098d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model('WGAN_2500epochs_500data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2509e78-58fd-4165-8d75-ee39c9d672eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676c03d-40f7-4ab5-aa2c-d9e9256f0f27",
   "metadata": {},
   "source": [
    "## Wasserstein + L1_Loss | 400train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d153d-8386-4383-853d-855f0e109dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "def generator_loss_W_L1(fake_output, denoised_images, target_images, sigma=10000, alpha = 1):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_images - denoised_images))\n",
    "    total_gen_loss = w_loss + sigma * (alpha * l1_loss)\n",
    "    \n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L1(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d460d2-2d71-4a58-8f33-54f121429e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(source_images)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(target_images)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 8\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70285b-59d5-4656-9f2c-7d9220862166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ba905-35bb-4b02-8bed-80f9c547bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 492, Generator Loss: 95.9011459350586, Discriminator Loss: -0.36895322799682617, PSNR: 40.37303924560547, SSIM: 0.9956716895103455\n",
    "generator.save('WGAN_L1_500epoch_500dataset_gen')\n",
    "discriminator.save('WGAN_L1_500epoch_500dataset_disc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583f879-adbf-4856-bed1-c0b7843aa1de",
   "metadata": {},
   "source": [
    "## Wasserstein + L2_Loss | 400train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d771d8-25f0-4b42-b19f-6147ffb4e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "def generator_loss_W_L2(fake_output, denoised_images, target_images, sigma=10000, alpha = 1):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l2_loss = tf.reduce_mean(tf.square(target_images - denoised_images))\n",
    "    total_gen_loss = w_loss + sigma * ( alpha * l2_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L2(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63758ce-bbeb-4541-acc9-2a5e6aff001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(source_images)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(target_images)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 8\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379948a-9011-4d38-85ea-d387e8755bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        avg_psnr = total_psnr / num_batches\n",
    "        avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {avg_psnr}, '\n",
    "              f'SSIM: {avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 500  \n",
    "train(dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545620e9-3acb-4c40-a578-0d000225266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L2_500epoch_500dataset_gen.h5')\n",
    "discriminator.save('WGAN_L2_500epoch_500dataset_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32f967-4097-4da7-9ad0-244ed7a20194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator = load_model('WGAN_L2_500epoch_500dataset_gen.h5')\n",
    "avg_psnr, avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "print(f\"psnr: {avg_psnr}, ssim {avg_ssim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac27c2-1e04-4eff-baba-8c10a19137b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model('WGAN_L2_500epoch_500dataset_gen.h5')\n",
    "generator.compile()\n",
    "\n",
    "predicted_images = generator.predict(test_images)\n",
    "random_indices = np.random.choice(len(test_images), 6, replace=False)\n",
    "\n",
    "for i in range(1,6):\n",
    "    original_image = normalize_image(test_images[i].squeeze())  \n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze()) \n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e7402-6f13-419d-a47d-c9812a8003df",
   "metadata": {},
   "source": [
    "## Wasserstein + L2_Loss | 900train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100da143-9dbd-4366-9c7c-8279238a60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "def generator_loss_W_L2(fake_output, denoised_images, target_images, sigma=10000, alpha = 1):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l2_loss = tf.reduce_mean(tf.square(target_images - denoised_images))\n",
    "    total_gen_loss = w_loss + sigma * ( alpha * l2_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L2(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8410f-6e6a-4ec0-b777-e232d0affebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 4\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae83fa7-451c-42b6-b90f-a792b09bf3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 500  \n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e7f11-f385-4c64-83a7-d0983904b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L2_500epoch_1000dataset_gen.h5')\n",
    "discriminator.save('WGAN_L2_500epoch_1000dataset_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53206754-a54b-43ee-92de-ca653b0bfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae7bc1-fcca-43eb-aaf0-a7fbbc0c63b9",
   "metadata": {},
   "source": [
    "## Wasserstein + L2_Loss + Perceptual | 1900train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf2988-1eed-4ea0-91d6-1483a244c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, input_shape=(None, None, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_layers = ['block5_conv4']\n",
    "vgg_model = tf.keras.Model([vgg.input], [vgg.get_layer(layer).output for layer in perceptual_layers])\n",
    "\n",
    "def perceptual_loss(generated, target):\n",
    "    gen_features = vgg_model(generated)\n",
    "    target_features = vgg_model(target)\n",
    "    return tf.reduce_mean(tf.square(target_features - gen_features))\n",
    "\n",
    "def generator_loss_W_L2_Perceptual(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l2_loss = tf.reduce_mean(tf.square(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    total_gen_loss = w_loss + sigma * (alpha * l2_loss + beta * p_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "#history_buffer = HistoryBuffer(max_size=8)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L2_Perceptual(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350a690-d935-49f9-88fc-466ad33d16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 8\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a50b8-c001-4c39-bd36-086168dfae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 1  \n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b7eba-a49d-45a9-ae97-9141e8ff9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L2Per_500epoch_2000dataset_gen.h5')\n",
    "discriminator.save('WGAN_L2Per_500epoch_2000dataset_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17582199-bc0a-4d4b-8240-82a0b145cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762e026-46af-4c9f-acc3-2299094ca0db",
   "metadata": {},
   "source": [
    "## Wasserstein + L2_Loss + Perceptual + Sobel | 1900train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1f90b-171f-4c24-9a77-1aeccb3cde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, input_shape=(None, None, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_layers = ['block5_conv4']\n",
    "vgg_model = tf.keras.Model([vgg.input], [vgg.get_layer(layer).output for layer in perceptual_layers])\n",
    "\n",
    "def perceptual_loss(generated, target):\n",
    "    gen_features = vgg_model(generated)\n",
    "    target_features = vgg_model(target)\n",
    "    return tf.reduce_mean(tf.square(target_features - gen_features))\n",
    "\n",
    "def sobel_loss(generated, target):\n",
    "    sobel_generated = tf.image.sobel_edges(generated)\n",
    "    sobel_target = tf.image.sobel_edges(target)\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(sobel_target - sobel_generated))\n",
    "\n",
    "def generator_loss_W_L2_Perceptual(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l2_loss = tf.reduce_mean(tf.square(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    total_gen_loss = w_loss + sigma * (alpha * l2_loss + beta * p_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "def generator_loss_W_L2_Perceptual_Sobel(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1, gamma=10):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l2_loss = tf.reduce_mean(tf.square(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    s_loss = sobel_loss(denoised_images, target_images)\n",
    "    \n",
    "    total_gen_loss = w_loss + sigma * (alpha * l2_loss + beta * p_loss + gamma * s_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L2_Perceptual_Sobel(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b9f23-b6f4-4595-84f3-59c61150826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 1  \n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe3598-bbf0-4067-a600-0d5b51b8efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L2Sob_850epoch_2000dataset_gen.h5')\n",
    "discriminator.save('WGAN_L2Sob_850epoch_2000dataset_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec66ed-f5bf-421c-97d0-4547c6b9215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 750 epochs | Generator Loss: 22.633766174316406, Discriminator Loss: -0.008981402032077312, PSNR: 49.84444046020508, SSIM: 0.9991695880889893, Validation PSNR: 39.01051330566406, Validation SSIM: 0.992892324924469, Time: 387.34 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cc661-de56-4615-ae67-e83606ef65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 850 epoch | Generator Loss: 18.908538818359375, Discriminator Loss: -0.011361256241798401, PSNR: 49.376426696777344, SSIM: 0.999204695224762, Validation PSNR: 39.010196685791016, Validation SSIM: 0.9930490255355835, Time: 386.87 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6adcf-a364-4ab7-8e5d-896a5efd65b0",
   "metadata": {},
   "source": [
    "## Wasserstein + L1_Loss + Perceptual + Sobel | 1900train + 100test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3fe28-2235-44f4-967c-5cbab71c4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, input_shape=(None, None, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_layers = ['block5_conv4']\n",
    "vgg_model = tf.keras.Model([vgg.input], [vgg.get_layer(layer).output for layer in perceptual_layers])\n",
    "\n",
    "def perceptual_loss(generated, target):\n",
    "    gen_features = vgg_model(generated)\n",
    "    target_features = vgg_model(target)\n",
    "    return tf.reduce_mean(tf.square(target_features - gen_features))\n",
    "\n",
    "def sobel_loss(generated, target):\n",
    "    sobel_generated = tf.image.sobel_edges(generated)\n",
    "    sobel_target = tf.image.sobel_edges(target)\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(sobel_target - sobel_generated))\n",
    "\n",
    "\n",
    "def generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1, gamma=10):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    s_loss = sobel_loss(denoised_images, target_images)\n",
    "    \n",
    "    total_gen_loss = w_loss + sigma * (alpha * l1_loss + beta * p_loss + gamma * s_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6dc00-59a1-461f-8c36-f7f6cb291a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33680f1-48c6-4464-b7d1-903b905f31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L1Sob_750epoch_2000dataset_gen.h5')\n",
    "discriminator.save('WGAN_L1Sob_750epoch_2000dataset_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb06f5e-641b-4303-b493-b26edbaf4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 Epoch | Generator Loss: 77.4582748413086, Discriminator Loss: -0.02741212397813797, PSNR: 48.36365509033203, SSIM: 0.9988846778869629, Validation PSNR: 40.32948303222656, Validation SSIM: 0.9937796592712402\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afeb35-771b-455b-9f50-5f27692660de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#750 epoch | Generator Loss: 59.79399490356445, Discriminator Loss: -0.009202822111546993, PSNR: 49.406856536865234, SSIM: 0.9992486834526062, Validation PSNR: 40.53458023071289, Validation SSIM: 0.9937618970870972, Time: 386.69 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e418b-ceee-4a39-955a-ee49acf84643",
   "metadata": {},
   "source": [
    "## Wasserstein + L1_Loss + Perceptual + Sobel | 3000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9eb7fd-9760-40dd-8228-b9e83fe61c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, input_shape=(None, None, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_layers = ['block5_conv4']\n",
    "vgg_model = tf.keras.Model([vgg.input], [vgg.get_layer(layer).output for layer in perceptual_layers])\n",
    "\n",
    "def perceptual_loss(generated, target):\n",
    "    gen_features = vgg_model(generated)\n",
    "    target_features = vgg_model(target)\n",
    "    return tf.reduce_mean(tf.square(target_features - gen_features))\n",
    "\n",
    "def sobel_loss(generated, target):\n",
    "    sobel_generated = tf.image.sobel_edges(generated)\n",
    "    sobel_target = tf.image.sobel_edges(target)\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(sobel_target - sobel_generated))\n",
    "\n",
    "\n",
    "def generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1, gamma=10):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    s_loss = sobel_loss(denoised_images, target_images)\n",
    "    \n",
    "    total_gen_loss = w_loss + sigma * (alpha * l1_loss + beta * p_loss + gamma * s_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "#history_buffer = HistoryBuffer(max_size=8)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90442cbc-06ad-4cef-b94a-7d467fc461fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(generator, X_val, y_val,batch_size= 4):\n",
    "    num_samples = len(X_val)\n",
    "    steps = num_samples // batch_size + (1 if num_samples % batch_size else 0)\n",
    "    \n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    for step in range(steps):\n",
    "        batch_start = step * batch_size\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        X_batch = X_val[batch_start:batch_end]\n",
    "        y_batch = y_val[batch_start:batch_end]\n",
    "        \n",
    "        predicted_batch = generator.predict(X_batch)\n",
    "        # Normalize images from [-1, 1] to [0, 1] for PSNR and SSIM calculations\n",
    "        predicted_batch = normalize_images(predicted_batch)\n",
    "        y_batch_normalized = normalize_images(y_batch)\n",
    "        \n",
    "        for i in range(batch_end - batch_start):\n",
    "            psnr_val = psnr(y_batch_normalized[i], predicted_batch[i])\n",
    "            ssim_val = ms_ssim_metric(y_batch_normalized[i], predicted_batch[i])\n",
    "            \n",
    "            psnr_values.append(psnr_val)\n",
    "            ssim_values.append(ssim_val)\n",
    "    \n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    \n",
    "    return avg_psnr, avg_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223554e1-8948-4871-b886-d9c6be77ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 4\n",
    "#dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7eb40e-c562-4685-8a64-ca3b390b7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 2\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ec640-8b83-49b2-a319-9b261cbce10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L1Sob_750epoch_3000dataset_gen.h5')\n",
    "discriminator.save('WGAN_L1Sob_750epoch_3000dataset_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800058b4-148f-41a5-b351-a7ad79c05dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 500 | Generator Loss: 60.009727478027344, Discriminator Loss: -0.004583950154483318, PSNR: 48.44008255004883, SSIM: 0.9990533590316772, Validation PSNR: 43.31389617919922, Validation SSIM: 0.9967049360275269, Time: 630.21 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af490264-0463-4db2-937f-8cfa0c56c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 750 | Generator Loss: 52.27979278564453, Discriminator Loss: -0.004730249289423227, PSNR: 49.8203239440918, SSIM: 0.9993076920509338, Validation PSNR: 44.08540344238281, Validation SSIM: 0.9968264102935791, Time: 624.27 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d3e12-3418-4e04-8cfa-39bf54311279",
   "metadata": {},
   "source": [
    "## Wasserstein + L1_Loss + Perceptual + Sobel | 1024x1024 1000/100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397dd042-0bdd-4554-a60e-0b4425123364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, input_shape=(None, None, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_layers = ['block5_conv4']\n",
    "vgg_model = tf.keras.Model([vgg.input], [vgg.get_layer(layer).output for layer in perceptual_layers])\n",
    "\n",
    "def perceptual_loss(generated, target):\n",
    "    gen_features = vgg_model(generated)\n",
    "    target_features = vgg_model(target)\n",
    "    return tf.reduce_mean(tf.square(target_features - gen_features))\n",
    "\n",
    "def sobel_loss(generated, target):\n",
    "    sobel_generated = tf.image.sobel_edges(generated)\n",
    "    sobel_target = tf.image.sobel_edges(target)\n",
    "\n",
    "    return tf.reduce_mean(tf.square(sobel_target - sobel_generated))\n",
    "\n",
    "\n",
    "def generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1, gamma=10):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    s_loss = sobel_loss(denoised_images, target_images)\n",
    "\n",
    "    total_gen_loss = w_loss + sigma * (alpha * l1_loss + beta * p_loss + gamma * s_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "\n",
    "#generator = generator_WGAN(input_shape=(1024, 1024, 3), n_filters=32)\n",
    "#generator.summary()\n",
    "#discriminator = discriminator_WGAN(input_shape=(1024, 1024, 3), n_filters=32)\n",
    "#discriminator.summary()\n",
    "\n",
    "generator = load_model('WGAN_L1Sob_100epoch_1100dataset_fullsize_gen.h5')\n",
    "discriminator = load_model('WGAN_L1Sob_100epoch_1100dataset_fullsize_disc.h5')\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "#history_buffer = HistoryBuffer(max_size=8)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac52c9-2d35-4d24-93ce-3713f78b244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 1\n",
    "#dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n",
    "dataset = dataset.shuffle(buffer_size=1100).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b311a4e-0816-40b5-b3ac-a1134fddb24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "              \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val,1)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc04ff-0432-4d25-babe-966c0f752a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L1Sob_500epoch_1100dataset_fullsize_gen.h5')\n",
    "discriminator.save('WGAN_L1Sob_500epoch_1100dataset_fullsize_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56628d-f100-4b9f-b8f0-fe37bb538fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch500train Generator Loss: 122.08033752441406, Discriminator Loss: -0.012598012574017048, PSNR: 34.723182678222656, SSIM: 0.9896923303604126, Time: 477.38 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c732e-6e1a-4a51-b14b-52d77cb1ab3c",
   "metadata": {},
   "source": [
    "# + fine-tune on inverse colors 3000dataset | 50 - 50 test set (50 normal, 50bitwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de27d0-cca4-498d-ad07-1eaa60131cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'Dataset/source'\n",
    "target_folder = 'Dataset/target'\n",
    "\n",
    "# List all image file names in the source folder\n",
    "source_image_files = os.listdir(source_folder)\n",
    "\n",
    "# Initialize lists to store the preprocessed images\n",
    "source_images = []\n",
    "target_images = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Loop through each image file in the source folder\n",
    "for filename in source_image_files:\n",
    "\n",
    "    # Load source image\n",
    "    source_image = cv2.imread(os.path.join(source_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    #source_image = source_image.astype('float32') / 255.0\n",
    "    if i > 50:\n",
    "        source_image = cv2.bitwise_not(source_image)\n",
    "    source_image = (source_image.astype(np.float32) - 127.5) / 127.5\n",
    "    source_image = np.repeat(source_image[:, :, np.newaxis], 3, axis=2)\n",
    "    source_image = cv2.resize(source_image, (512, 512))\n",
    "    source_images.append(source_image)\n",
    "\n",
    "    # Load corresponding target image from the target folder\n",
    "    target_image = cv2.imread(os.path.join(target_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    #target_image = target_image.astype('float32') / 255.0\n",
    "    if i > 50:\n",
    "        target_image = cv2.bitwise_not(target_image)\n",
    "    target_image = (target_image.astype(np.float32) - 127.5) / 127.5\n",
    "    target_image = np.repeat(target_image[:, :, np.newaxis], 3, axis=2)\n",
    "    target_image = cv2.resize(target_image, (512, 512))\n",
    "    target_images.append(target_image)\n",
    "       \n",
    "    i += 1\n",
    "    if i == 3100:\n",
    "        break\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "source_images = np.array(source_images)\n",
    "target_images = np.array(target_images)\n",
    "\n",
    "#source_images = np.expand_dims(source_images, axis=-1)\n",
    "#target_images = np.expand_dims(target_images, axis=-1)\n",
    "# Print the shape of the loaded and preprocessed images\n",
    "print(\"Source Images Shape:\", source_images.shape)\n",
    "print(\"Target Images Shape:\", target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fce514-937a-446b-a110-1d347704f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first 100 as a test set\n",
    "X_train = source_images[100:]\n",
    "y_train = target_images[100:]\n",
    "\n",
    "X_val = source_images[:100]\n",
    "y_val = target_images[:100]\n",
    "\n",
    "print(f\"x_train: {len(X_train)} | x_val: {len(X_val)} | y_train: {len(y_train)} | y_val: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338750b-5ad1-4107-85ae-b32cc1a6312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, axs = plt.subplots(2, 5)\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "      if i == 0:\n",
    "            axs[i, j].imshow(normalize_images(source_images[j]), cmap='gray')\n",
    "            axs[i, j].set_title('Source image')\n",
    "            axs[i, j].axis('off')\n",
    "      else:\n",
    "            axs[i, j].imshow(normalize_images(target_images[j]), cmap='gray')\n",
    "            axs[i, j].set_title('Target image')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e4c92-ec98-4c60-9924-a2707e23cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, input_shape=(None, None, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_layers = ['block5_conv4']\n",
    "vgg_model = tf.keras.Model([vgg.input], [vgg.get_layer(layer).output for layer in perceptual_layers])\n",
    "\n",
    "def perceptual_loss(generated, target):\n",
    "    gen_features = vgg_model(generated)\n",
    "    target_features = vgg_model(target)\n",
    "    return tf.reduce_mean(tf.square(target_features - gen_features))\n",
    "\n",
    "def sobel_loss(generated, target):\n",
    "    sobel_generated = tf.image.sobel_edges(generated)\n",
    "    sobel_target = tf.image.sobel_edges(target)\n",
    "    \n",
    "    return tf.reduce_mean(tf.square(sobel_target - sobel_generated))\n",
    "\n",
    "\n",
    "def generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, target_images, beta=10, sigma=10000, alpha=1, gamma=10):\n",
    "    w_loss = -tf.reduce_mean(fake_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_images - denoised_images))\n",
    "    p_loss = perceptual_loss(denoised_images, target_images)\n",
    "    s_loss = sobel_loss(denoised_images, target_images)\n",
    "    \n",
    "    total_gen_loss = w_loss + sigma * (alpha * l1_loss + beta * p_loss + gamma * s_loss)\n",
    "    return total_gen_loss\n",
    "\n",
    "\n",
    "generator = load_model('WGAN_L1Sob_750epoch_3000dataset_gen.h5')\n",
    "discriminator = load_model('WGAN_L1Sob_750epoch_3000dataset_disc.h5')\n",
    "\n",
    "#generator = generator_WGAN(input_shape=(512, 512, 3))\n",
    "#discriminator = discriminator_WGAN(input_shape=(512, 512, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "\n",
    "generator.compile(optimizer=generator_optimizer,\n",
    "              loss=generator_loss_W_L1_Perceptual_Sobel,\n",
    "              metrics=[psnr, ms_ssim_metric])\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "              loss=discriminator_loss,\n",
    "              metrics=[psnr, ms_ssim_metric])\n",
    "\n",
    "#history_buffer = HistoryBuffer(max_size=8)\n",
    "\n",
    "@tf.function\n",
    "def train_step(noisy_img_batch, clean_img_batch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        denoised_images = generator(noisy_img_batch, training=True)\n",
    "        real_output = discriminator(clean_img_batch, training=True)\n",
    "        fake_output = discriminator(denoised_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss_W_L1_Perceptual_Sobel(fake_output, denoised_images, clean_img_batch)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Clip discriminator weights\n",
    "    for w in discriminator.trainable_variables:\n",
    "        w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1401ce4-d7d0-4e32-a62b-3e72f2dd6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "clean_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "dataset = tf.data.Dataset.zip((noisy_dataset, clean_dataset))\n",
    "BATCH_SIZE = 4\n",
    "#dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a962031-3a6d-476e-9377-0975c6ecc6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, X_val, y_val):\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        total_psnr = 0\n",
    "        total_ssim = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for noisy_img_batch, clean_img_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(noisy_img_batch, clean_img_batch)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_disc_loss += disc_loss\n",
    "            \n",
    "            denoised_images = generator(noisy_img_batch, training=False)\n",
    "            \n",
    "            norm_denoised_images = normalize_images(denoised_images)\n",
    "            norm_clean_img_batch = normalize_images(clean_img_batch)\n",
    "            \n",
    "            batch_psnr = tf.reduce_mean(psnr(norm_denoised_images, norm_clean_img_batch))\n",
    "            batch_ssim = tf.reduce_mean(ms_ssim_metric(norm_denoised_images, norm_clean_img_batch))\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_ssim += batch_ssim\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            \n",
    "        val_avg_psnr, val_avg_ssim = evaluate_on_test_set(generator, X_val, y_val)\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_disc_loss = total_disc_loss / num_batches\n",
    "        train_avg_psnr = total_psnr / num_batches\n",
    "        train_avg_ssim = total_ssim / num_batches\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        total_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
    "              f'Generator Loss: {avg_gen_loss}, '\n",
    "              f'Discriminator Loss: {avg_disc_loss}, '\n",
    "              f'PSNR: {train_avg_psnr}, '\n",
    "              f'SSIM: {train_avg_ssim}, '\n",
    "              f'Validation PSNR: {val_avg_psnr}, '\n",
    "              f'Validation SSIM: {val_avg_ssim}, '\n",
    "              f'Time: {epoch_duration:.2f} sec')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            display_images(noisy_img_batch, epoch + 1)\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "train(dataset, EPOCHS, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906784ca-07cc-4fc1-b2e7-36a0fa256136",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('WGAN_L1Sob_500epoch_3000dataset_invert_gen.h5')\n",
    "discriminator.save('WGAN_L1Sob_500epoch_3000dataset_invert_disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6815d0e-4fc0-4d75-a4e0-7e4cc559bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 250 | Generator Loss: 67.63257598876953, Discriminator Loss: -0.01677171140909195, PSNR: 47.56999969482422, SSIM: 0.9988458752632141, Validation PSNR: 33.62474060058594, Validation SSIM: 0.9820313453674316, Time: 634.36 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289bae8-bc79-4ae0-8c60-c0d3c38936b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 epochs | Generator Loss: 50.092411041259766, Discriminator Loss: -0.003123227972537279, PSNR: 48.603302001953125, SSIM: 0.9992698431015015, Validation PSNR: 33.26730728149414, Validation SSIM: 0.9800387024879456, Time: 627.18 sec\n",
    "predicted_images = None\n",
    "predicted_images = generator.predict(test_images)\n",
    "num_samples_to_visualize = 6\n",
    "random_indices = np.random.choice(len(test_images), num_samples_to_visualize)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    original_image = normalize_image(test_images[i].squeeze())\n",
    "    predicted_image = normalize_image(predicted_images[i].squeeze())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.imshow(predicted_image, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
